{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"6.Recurrent_Neural_Network.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"IFErWZFyC7cx"},"source":["## library import\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","\n","print(tf.__version__)\n","print(keras.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cDH9IFkvpexS"},"source":["# RNN을 이용하여 MNIST Classification 학습하기 \n","  \n","\n","MNIST Image를 한 line씩 RNN에 입력하여 classification을 하는 실습을 해보겠습니다."]},{"cell_type":"code","metadata":{"id":"6aFxV5JNdK6z"},"source":["## Hyper-parameters\n","learning_rate = 0.001\n","N_EPOCHS = 20\n","N_BATCH = 100\n","N_CLASS = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"miNAOFXNpl8T"},"source":["## Data 준비\n","## MNIST Dataset #########################################################\n","mnist = keras.datasets.mnist\n","class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n","##########################################################################\n","\n","## Fashion MNIST Dataset #################################################\n","#mnist = keras.datasets.fashion_mnist\n","#class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n","##########################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MWXMlAvBprPr"},"source":["## Dataset 만들기\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","N_TRAIN = train_images.shape[0]\n","N_TEST = test_images.shape[0]\n","print(train_images.shape, test_images.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RddODKrhpypG"},"source":["# pixel값을 0~1사이 범위로 조정\n","train_images = train_images.astype(np.float32) / 255.\n","test_images = test_images.astype(np.float32) / 255.\n","\n","# label을 onehot-encoding\n","train_labels = to_categorical(train_labels, 10)\n","test_labels = to_categorical(test_labels, 10)    \n","\n","# Dataset 구성\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(\n","                buffer_size=100000).batch(N_BATCH)\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(N_BATCH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yTG07duup1hk"},"source":["## Model 만들기\n","def create_model():\n","    model = keras.Sequential()\n","    model.add(layers.LSTM(units=256, return_sequences=False, input_shape=(28,28)))\n","    model.add(layers.Dense(units=10, activation='softmax'))\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cDs9Ff3nqOgQ"},"source":["## Create model, compile & summary\n","model = create_model()\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aMqlbyR1NVbC"},"source":["## 학습 전에 결과 확인\n","model.evaluate(test_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bAL4CxnLrb0i"},"source":["## Training\n","history = model.fit(train_dataset, epochs=N_EPOCHS, \n","                    validation_data=test_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DktblJMwreQ5"},"source":["## 결과 확인\n","def plot_image(i, predictions_array, true_label, img):\n","    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n","    plt.grid(False)\n","    plt.xticks([])\n","    plt.yticks([])\n","\n","    plt.imshow(img,cmap=plt.cm.binary)\n","\n","    predicted_label = np.argmax(predictions_array)\n","    if predicted_label == true_label:\n","        color = 'blue'\n","    else:\n","        color = 'red'\n","\n","    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n","                                100*np.max(predictions_array),\n","                                class_names[true_label]),\n","                                color=color)\n","\n","def plot_value_array(i, predictions_array, true_label):\n","    predictions_array, true_label = predictions_array[i], true_label[i]\n","    plt.grid(False)\n","    #plt.xticks([])\n","    plt.xticks(range(N_CLASS), class_names, rotation=90)\n","    plt.yticks([])\n","    thisplot = plt.bar(range(N_CLASS), predictions_array, color=\"#777777\")\n","    plt.ylim([0, 1]) \n","    predicted_label = np.argmax(predictions_array)\n"," \n","    thisplot[predicted_label].set_color('red')\n","    thisplot[true_label].set_color('blue')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d8o6MGhtryj7"},"source":["rnd_idx = np.random.randint(1, N_TEST//N_BATCH)\n","img_cnt = 0\n","for images, labels in test_dataset:\n","    img_cnt += 1\n","    if img_cnt != rnd_idx:\n","        continue\n","    predictions = model(images, training=False)\n","    num_rows = 5\n","    num_cols = 3\n","    num_images = num_rows*num_cols\n","    labels = tf.argmax(labels, axis=-1)\n","    plt.figure(figsize=(3*2*num_cols, 4*num_rows))\n","    plt.subplots_adjust(hspace=1.0)\n","    for i in range(num_images):\n","        plt.subplot(num_rows, 2*num_cols, 2*i+1)\n","        plot_image(i, predictions.numpy(), labels.numpy(), images.numpy())\n","        plt.subplot(num_rows, 2*num_cols, 2*i+2)\n","        plot_value_array(i, predictions.numpy(), labels.numpy())        \n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bb9hbaZGsLb7"},"source":["# Simple Language Model with RNN\n","\n","RNN을 이용하여 간단한 language model을 학습시켜 보겠습니다."]},{"cell_type":"code","metadata":{"id":"mVo2uGX0r3nK"},"source":["## 학습시킬 문장\n","sentence = (\"if you want to build a ship, don't drum up people together to \"\n","            \"collect wood and don't assign them tasks and work, but rather \"\n","            \"teach them to long for the endless immensity of the sea.\")\n","\n","## index를 주면 charcter로 바꿔주는 list\n","idx2char = list(set(sentence))\n","## character를 주면 index로 바꿔주는 dictionary\n","char2idx = {w: i for i, w in enumerate(idx2char)}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"URoWK4z5sRgt"},"source":["idx2char, len(idx2char)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vxq8FLjTsTZI"},"source":["char2idx"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4CaTSzEtsVjn"},"source":["## HyperParameters\n","data_dim = len(idx2char)\n","hidden_size = len(idx2char)\n","num_classes = len(idx2char)\n","sequence_length = 10  # Any arbitrary number\n","learning_rate = 0.1\n","training_epochs = 200\n","print(num_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z8DCEctHsZ-F"},"source":["## Dataset\n","dataX = []\n","dataY = []\n","for i in range(0, len(sentence) - sequence_length):\n","    x_str = sentence[i:i + sequence_length]\n","    y_str = sentence[i + 1: i + sequence_length + 1]\n","    print(i, x_str, '->', y_str)\n","\n","    x = [char2idx[c] for c in x_str]  # x str to index\n","    y = [char2idx[c] for c in y_str]  # y str to index\n","\n","    dataX.append(x)\n","    dataY.append(y)\n","\n","batch_size = len(dataX)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SAbaS2jnseGn"},"source":["dataX = np.array(to_categorical(dataX, num_classes))\n","dataY = np.array(to_categorical(dataY, num_classes))\n","print(dataX.shape, dataY.shape)\n","print(batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RzdU7Y0IsifS"},"source":["train_dataset = tf.data.Dataset.from_tensor_slices((dataX, dataY)).shuffle(\n","                buffer_size=1000).batch(batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JEBqkm0islcM"},"source":["## Model 만들기\n","def create_model():\n","    model = keras.Sequential()\n","    model.add(layers.LSTM(units=hidden_size, return_sequences=True,\n","                                     input_shape=(dataX.shape[1],dataX.shape[2])))\n","    model.add(layers.LSTM(units=hidden_size, return_sequences=True))\n","    model.add(layers.Dense(units=num_classes, activation='softmax'))\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gVKvCmOnspAo"},"source":["model = create_model()\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate),\n","              loss='categorical_crossentropy')\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"94NcFnNxtKCJ"},"source":["## Training\n","model.fit(train_dataset, epochs=training_epochs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mSFZUaWhtKri"},"source":["## 결과 확인\n","results = model.predict(dataX, steps=1)\n","for j, result in enumerate(results):\n","    index = np.argmax(result, axis=1)\n","    if j is 0:  # print all for the first result to make a sentence\n","        print(''.join([idx2char[t] for t in index]), end='')\n","    else:\n","        print(idx2char[index[-1]], end='')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rnupGB2fuNWc"},"source":["# Stock Prediction with RNN  \n","RNN을 이용한 간단한 주식 예측 모델을 학습해보겠습니다."]},{"cell_type":"code","metadata":{"id":"kt3TNpW8MzvP"},"source":["## google drive 연동\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FQjHP119uKrj"},"source":["## HyperParameters\n","seq_length = 7\n","data_dim = 5\n","hidden_size = 10\n","output_dim = 1\n","learning_rate = 0.001\n","training_epochs = 100\n","batch_size = 32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JpeWgQD1ucQO"},"source":["## Data Preprocessing\n","def MinMaxScaler(data):\n","    ''' Min Max Normalization\n","    Parameters\n","    ----------\n","    data : numpy.ndarray\n","        input data to be normalized\n","        shape: [Batch size, dimension]\n","    Returns\n","    ----------\n","    data : numpy.ndarry\n","        normalized data\n","        shape: [Batch size, dimension]\n","    References\n","    ----------\n","    .. [1] http://sebastianraschka.com/Articles/2014_about_feature_scaling.html\n","    '''\n","    numerator = data - np.min(data, 0)\n","    denominator = np.max(data, 0) - np.min(data, 0)\n","    print(denominator)\n","    print(np.min(data, 0))\n","    # noise term prevents the zero division\n","    result = numerator / (denominator + 1e-7)\n","    return result, denominator[-1], np.min(data, 0)[-1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y1dGsEA8ujDN"},"source":["## Data 준비\n","# Open, High, Low, Volume, Close\n","xy = np.loadtxt('/content/drive/My Drive/ssac/data/hyundai.csv', delimiter=',')\n","xy, denom, min = MinMaxScaler(xy)\n","xy = xy.astype(np.float32)\n","x = xy\n","y = xy[:, [-1]]  # Close as label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gRuz1NnevZxN"},"source":["# build a dataset\n","dataX = []\n","dataY = []\n","for i in range(0, len(y) - seq_length):\n","    _x = x[i:i + seq_length]\n","    _y = y[i + seq_length]  # Next close price\n","    if i % 100 == 0:\n","      print(_x, \"->\", _y)\n","    dataX.append(_x)\n","    dataY.append(_y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NbBoWcTUvkZr"},"source":["## Train/Test Split\n","train_size = int(len(dataY) * 0.7-2)\n","test_size = len(dataY) - train_size\n","trainX, testX = np.array(dataX[0:train_size]), np.array(\n","    dataX[train_size:len(dataX)])\n","trainY, testY = np.array(dataY[0:train_size]), np.array(\n","    dataY[train_size:len(dataY)])\n","print(trainX.shape, trainY.shape)\n","print(testX.shape, testY.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wwYwY6Qrvqa5"},"source":["## Dataset 만들기\n","train_dataset = tf.data.Dataset.from_tensor_slices((trainX, trainY)).shuffle(\n","                buffer_size=3000).prefetch(buffer_size=batch_size).batch(batch_size)\n","test_dataset = tf.data.Dataset.from_tensor_slices((testX, testY)).prefetch(\n","                buffer_size=batch_size).batch(batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J-ZYSt02vt9j"},"source":["## Model 만들기\n","def create_model():\n","    model = keras.Sequential()\n","    model.add(keras.layers.LSTM(units=hidden_size, return_sequences=True,\n","                                     input_shape=(trainX.shape[1],trainX.shape[2])))\n","    model.add(keras.layers.LSTM(units=hidden_size))\n","    model.add(keras.layers.Dense(units=output_dim))\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nR-XF5EWvyCq"},"source":["model = create_model()\n","model.compile(optimizer=keras.optimizers.RMSprop(learning_rate),\n","              loss='mse',\n","              metrics=[keras.metrics.RootMeanSquaredError()])\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bOabov-WwA9f"},"source":["## Training\n","model.fit(train_dataset, epochs=training_epochs,\n","          validation_data=test_dataset)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fPkCedO1wEwb"},"source":["## 결과확인\n","prediction = model.predict(test_dataset)\n","plt.figure(figsize=(15,7))\n","plt.plot(testY)\n","plt.plot(prediction)\n","plt.xlabel(\"Time Period\")\n","plt.ylabel(\"Stock Price\")\n","plt.legend(['real', 'prediction'])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S2jcsE4EjJu4"},"source":["test_input = np.reshape(x[-7:], (-1, 7, 5))\r\n","test_input.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u4Dt0Kp2pABC"},"source":["final_predict = model.predict(test_input)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_E7VYQvmpH7N"},"source":["final_predict * (denom + 1e-7) + min"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKdabfhfw0Ml"},"source":[""],"execution_count":null,"outputs":[]}]}